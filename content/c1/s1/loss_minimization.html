

<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta charset="utf-8" />
    <title>Approach 1: Minimizing Loss &#8212; Machine Learning from Scratch</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/all.min.css" integrity="sha384-KA6wR/X5RY4zFAHpv/CnoG2UW1uogYfdnP67Uv7eULvTveboZJg0qUpmJZb5VqzN" crossorigin="anonymous">
    <link href="../../../_static/css/index.css" rel="stylesheet">
    <link rel="stylesheet" href="../../../_static/sphinx-book-theme.css" type="text/css" />
    <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/jupyter-sphinx.css" />
    <script id="documentation_options" data-url_root="../../../" src="../../../_static/documentation_options.js"></script>
    <script src="../../../_static/sphinx-book-theme.js"></script>
    <script src="../../../_static/jquery.js"></script>
    <script src="../../../_static/underscore.js"></script>
    <script src="../../../_static/doctools.js"></script>
    <script src="../../../_static/language_data.js"></script>
    <script src="../../../_static/togglebutton.js"></script>
    <script src="../../../_static/clipboard.min.js"></script>
    <script src="../../../_static/copybutton.js"></script>
    <script src="../../../_static/mystnb.js"></script>
    <script src="../../../_static/sphinx-book-theme.js"></script>
    <script >var togglebuttonSelector = '.toggle, .secondtoggle, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.18.0/dist/embed-amd.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"TeX": {"Macros": {"sumN": "\\sum_{n = 1}^N", "sumn": "\\sum_{n}", "prodN": "\\prod_{n = 1}^N", "bx": "\\mathbf{x}", "by": "\\mathbf{y}", "bX": "\\mathbf{X}", "bY": "\\mathbf{Y}", "bT": "\\mathbf{T}", "bbeta": "\\boldsymbol{\\beta}", "btheta": "\\boldsymbol{\\hat{\\theta}}}", "bmu": "\\boldsymbol{\\mu}", "bSigma": "\\boldsymbol{\\Sigma}", "bbetahat": "\\boldsymbol{\\hat{\\beta}}", "bbR": "\\mathbb{R}", "iid": "\\overset{\\small{\\text{i.i.d.}}}{\\sim}}", "dadb": ["{\\frac{\\partial #1}{\\partial #2}}", 2], "testing": "\\TeX", "R": "\\mathbb{R}"}}})</script>
    <link rel="shortcut icon" href="../../../_static/logo.png"/>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
    <link rel="next" title="Approach 2: Maximizing Likelihood" href="likelihood_maximization.html" />
    <link rel="prev" title="Concept" href="../concept.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="docsearch:language" content="en">



  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../../../index.html">
  
  <img src="../../../_static/logo.png" class="logo" alt="logo">
  
  
  <h1 class="site-logo" id="site-title">Machine Learning from Scratch</h1>
  
</a>
</div>

<form class="bd-search d-flex align-items-center" action="../../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form>

<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  
  <ul class="nav sidenav_l1">
  <li class="">
    <a href="../../table_of_contents.html">Table of Contents</a>
  </li>
  <li class="">
    <a href="../../conventions_notation.html">Conventions and Notation</a>
  </li>
<li class="navbar-special">
<p class="margin-caption">1. Ordinary Linear Regression</p>
</li>
  <li class="active">
    <a href="../concept.html">Concept</a>
  <ul class="nav sidenav_l2">
    <li class="active">
      <a href="">Approach 1: Minimizing Loss</a>
    </li>
    <li class="">
      <a href="likelihood_maximization.html">Approach 2: Maximizing Likelihood</a>
    </li>
  </ul>
  </li>
  <li class="">
    <a href="../construction.html">Construction</a>
  </li>
  <li class="">
    <a href="../code.html">Code</a>
  </li>
<li class="navbar-special">
<p class="margin-caption">2. Linear Regression Extensions</p>
</li>
  <li class="">
    <a href="../../c2/concept.html">Concept</a>
  </li>
  <li class="">
    <a href="../../c2/construction.html">Construction</a>
  </li>
  <li class="">
    <a href="../../c2/code.html">Code</a>
  </li>
<li class="navbar-special">
<p class="margin-caption">3. Discriminative Classifiers (Logistic Regression)</p>
</li>
  <li class="">
    <a href="../../c3/concept.html">Concept</a>
  </li>
  <li class="">
    <a href="../../c3/construction.html">Construction</a>
  </li>
  <li class="">
    <a href="../../c3/code.html">Code</a>
  </li>
<li class="navbar-special">
<p class="margin-caption">4. Generative Classifiers (Naive Bayes)</p>
</li>
  <li class="">
    <a href="../../c4/concept.html">Concept</a>
  </li>
  <li class="">
    <a href="../../c4/construction.html">Construction</a>
  </li>
  <li class="">
    <a href="../../c4/code.html">Code</a>
  </li>
<li class="navbar-special">
<p class="margin-caption">5. Decision Trees</p>
</li>
  <li class="">
    <a href="../../c5/concept.html">Concept</a>
  </li>
  <li class="">
    <a href="../../c5/construction.html">Construction</a>
  </li>
  <li class="">
    <a href="../../c5/code.html">Code</a>
  </li>
<li class="navbar-special">
<p class="margin-caption">6. Tree Ensemble Methods</p>
</li>
  <li class="">
    <a href="../../c6/concept.html">Concept</a>
  </li>
  <li class="">
    <a href="../../c6/construction.html">Construction</a>
  </li>
  <li class="">
    <a href="../../c6/code.html">Code</a>
  </li>
<li class="navbar-special">
<p class="margin-caption">7. Neural Networks</p>
</li>
  <li class="">
    <a href="../../c7/concept.html">Concept</a>
  </li>
  <li class="">
    <a href="../../c7/construction.html">Construction</a>
  </li>
  <li class="">
    <a href="../../c7/code.html">Code</a>
  </li>
<li class="navbar-special">
<p class="margin-caption">Appendix</p>
</li>
  <li class="">
    <a href="../../appendix/math.html">Math</a>
  </li>
  <li class="">
    <a href="../../appendix/probability.html">Probability</a>
  </li>
  <li class="">
    <a href="../../appendix/methods.html">Common Methods</a>
  </li>
  <li class="">
    <a href="../../appendix/data.html">Datasets</a>
  </li>
</ul>
</nav>

 <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="row topbar fixed-top container-xl">
    <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show">
    </div>
    <div class="col pl-2 topbar-main">
        
        <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse" data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu" aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation" title="Toggle navigation" data-toggle="tooltip" data-placement="left">
            <i class="fas fa-bars"></i>
            <i class="fas fa-arrow-left"></i>
            <i class="fas fa-arrow-up"></i>
        </button>
        
        <div class="dropdown-buttons-trigger">
            <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i class="fas fa-download"></i></button>

            
            <div class="dropdown-buttons">
                <!-- ipynb file if we had a myst markdown file -->
                
                <!-- Download raw file -->
                <a class="dropdown-buttons" href="../../../_sources/content/c1/s1/loss_minimization.md.txt"><button type="button" class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip" data-placement="left">.md</button></a>
                <!-- Download PDF via print -->
                <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF" onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
            </div>
            
        </div>

        <!-- Edit this page -->
        <a class="edit-button" href="https://github.com/dafriedman97/mlbook/edit/master/content/c1/s1/loss_minimization.md"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="bottom" title="Edit this page"><i class="fas fa-pencil-alt"></i></button></a>

        <!-- Full screen (wrap in <a> to have style consistency -->
        <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="bottom" onclick="toggleFullScreen()" title="Fullscreen mode"><i class="fas fa-expand"></i></button></a>

        <!-- Launch buttons -->
        
    </div>
    <div class="d-none d-md-block col-md-2 bd-toc show">
<div class="tocsection onthispage pt-5 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="nav section-nav flex-column">
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#simple-linear-regression" class="nav-link">1. Simple Linear Regression</a><ul class="nav section-nav flex-column">
                
        <li class="nav-item toc-entry toc-h3">
            <a href="#model-structure" class="nav-link">Model Structure</a>
        </li>
    
        <li class="nav-item toc-entry toc-h3">
            <a href="#parameter-estimation" class="nav-link">Parameter Estimation</a>
        </li>
    
            </ul>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#multiple-regression" class="nav-link">2. Multiple Regression</a><ul class="nav section-nav flex-column">
                
        <li class="nav-item toc-entry toc-h3">
            <a href="#id1" class="nav-link">Model Structure</a>
        </li>
    
        <li class="nav-item toc-entry toc-h3">
            <a href="#id2" class="nav-link">Parameter Estimation</a>
        </li>
    
            </ul>
        </li>
    
    </ul>
</nav>



<div class="tocsection editthispage">
    <a href="https://github.com/dafriedman97/mlbook/edit/master/content/c1/s1/loss_minimization.md">
        <i class="fas fa-pencil-alt"></i> Edit this page
    </a>
</div>

    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="approach-1-minimizing-loss">
<h1>Approach 1: Minimizing Loss<a class="headerlink" href="#approach-1-minimizing-loss" title="Permalink to this headline">¶</a></h1>
<div class="math notranslate nohighlight">
\[
\newcommand{\sumN}{\sum_{n = 1}^N}
\newcommand{\sumn}{\sum_n}
\newcommand{\prodN}{\prod_{n = 1}^N}
\newcommand{\by}{\mathbf{y}} \newcommand{\bX}{\mathbf{X}}
\newcommand{\bx}{\mathbf{x}}
\newcommand{\bbeta}{\boldsymbol{\beta}}
\newcommand{\btheta}{\boldsymbol{\theta}}
\newcommand{\bbetahat}{\boldsymbol{\hat{\beta}}}
\newcommand{\bthetahat}{\boldsymbol{\hat{\theta}}}
\newcommand{\bSigma}{\boldsymbol{\Sigma}}
\newcommand{\bphi}{\boldsymbol{\phi}}
\newcommand{\bPhi}{\boldsymbol{\Phi}}
\newcommand{\bT}{\mathbf{T}}
\newcommand{\dadb}[2]{\frac{\partial #1}{\partial #2}}
\newcommand{\iid}{\overset{\small{\text{i.i.d.}}}{\sim}}
\]</div>
<div class="section" id="simple-linear-regression">
<h2>1. Simple Linear Regression<a class="headerlink" href="#simple-linear-regression" title="Permalink to this headline">¶</a></h2>
<div class="section" id="model-structure">
<h3>Model Structure<a class="headerlink" href="#model-structure" title="Permalink to this headline">¶</a></h3>
<p><em>Simple linear regression</em> models the target variable, <span class="math notranslate nohighlight">\(y\)</span>, as a linear function of just one predictor variable, <span class="math notranslate nohighlight">\(x\)</span>, plus an error term, <span class="math notranslate nohighlight">\(\epsilon\)</span>. We can write the entire model for the <span class="math notranslate nohighlight">\(n^\text{th}\)</span> observation as</p>
<div class="math notranslate nohighlight">
\[
\begin{align*}
y_n &amp;= \beta_0 + \beta_1 x_n + \epsilon_n.
\end{align*}
\]</div>
<p>Fitting the model then consists of estimating two parameters: <span class="math notranslate nohighlight">\(\beta_0\)</span> and <span class="math notranslate nohighlight">\(\beta_1\)</span>. We call our estimates of these parameters <span class="math notranslate nohighlight">\(\hat{\beta}_0\)</span> and <span class="math notranslate nohighlight">\(\hat{\beta}_1\)</span>, respectively. Once we’ve made these estimates, we can form our prediction for any given <span class="math notranslate nohighlight">\(x_n\)</span> with</p>
<div class="math notranslate nohighlight">
\[
\hat{y}_n = \hat{\beta}_0 + \hat{\beta}_1 x_n. 
\]</div>
<p>One way to find these estimates is by minimizing a loss function. Typically, this loss function is the <em>residual sum of squares</em> (RSS). The RSS is calculated with</p>
<div class="math notranslate nohighlight">
\[
\begin{align*}
\mathcal{L}(\hat{\beta}_0, \hat{\beta}_1) &amp;= \frac{1}{2}\sumN \left(y_n - \hat{y}_n\right)^2.
\end{align*}
\]</div>
<p>We divide the sum of squared errors by 2 in order to simplify the math, as shown below. Note that doing this does not affect our estimates because it does not affect which <span class="math notranslate nohighlight">\(\hat{\beta}_0\)</span> and <span class="math notranslate nohighlight">\(\hat{\beta}_1\)</span> minimize the RSS.</p>
</div>
<div class="section" id="parameter-estimation">
<h3>Parameter Estimation<a class="headerlink" href="#parameter-estimation" title="Permalink to this headline">¶</a></h3>
<p>Having chosen a loss function, we are ready to derive our estimates. First, let’s rewrite the RSS in terms of the estimates:</p>
<div class="math notranslate nohighlight">
\[
\mathcal{L}(\hat{\beta}_0, \hat{\beta}_1) = \frac{1}{2}\sumN\left(y_n - \left(\hat{\beta}_0 + \hat{\beta}_1x_n\right)\right)^2.
\]</div>
<p>To find the intercept estimate, start by taking the derivative of the RSS with respect to <span class="math notranslate nohighlight">\(\hat{\beta}_0\)</span>:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
\dadb{\mathcal{L}(\hat{\beta}_0, \hat{\beta}_1)}{\hat{\beta}_0} &amp;= -\sumN \left(y_n - \hat{\beta}_0 - \hat{\beta}_1x_n\right)  \\
&amp;= -N(\bar{y} - \hat{\beta}_0 - \hat{\beta}_1\bar{x}),
\end{align}
\end{split}\]</div>
<p>where <span class="math notranslate nohighlight">\(\bar{y}\)</span> and <span class="math notranslate nohighlight">\(\bar{x}\)</span> are the sample means. Then set that derivative equal to 0 and solve for <span class="math notranslate nohighlight">\(\hat{\beta}_0\)</span>:</p>
<div class="math notranslate nohighlight">
\[
\begin{align*}
\hat{\beta}_0 &amp;= \bar{y} - \hat{\beta}_1\bar{x}.
\end{align*}
\]</div>
<p>This gives our intercept estimate, <span class="math notranslate nohighlight">\(\hat{\beta}_0\)</span>, in terms of the slope estimate, <span class="math notranslate nohighlight">\(\hat{\beta}_1\)</span>. To find the slope estimate, again start by taking the derivative of the RSS:</p>
<div class="math notranslate nohighlight">
\[
\begin{align}
\dadb{\mathcal{L}(\hat{\beta}_0, \hat{\beta}_1)}{\hat{\beta}_1} &amp;= - \sumN \left(y_n - \hat{\beta}_0 - \hat{\beta}_1 x_n\right)x_n.
\end{align}
\]</div>
<p>Setting this equal to 0 and substituting for <span class="math notranslate nohighlight">\(\hat{\beta}_0\)</span>, we get</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
\sumN \left(y_n - (\bar{y} - \hat{\beta}_1 \bar{x}) - \hat{\beta}_1 x_n\right)x_n &amp;= 0
\\
\hat{\beta}_1\sumN (x_n-\bar{x})x_n &amp;= \sumN \left(y_n - \bar{y}\right)x_n 
\\
\hat{\beta}_1 &amp;= \frac{\sumN x_n(y_n - \bar{y})}{\sumN x_n(x_n - \bar{x})}.
\end{align*}
\end{split}\]</div>
<p>To put this in a more standard form, we use a slight algebra trick. Note that</p>
<div class="math notranslate nohighlight">
\[
\sumN c(z_n - \bar{z}) = 0
\]</div>
<p>for any constant <span class="math notranslate nohighlight">\(c\)</span> and any collection <span class="math notranslate nohighlight">\(z_1, \dots, z_N\)</span> with sample mean <span class="math notranslate nohighlight">\(\bar{z}\)</span> (this can easily be verified by expanding the sum). Since <span class="math notranslate nohighlight">\(\bar{x}\)</span> is a constant, we can then subtract  <span class="math notranslate nohighlight">\(\sumN \bar{x}(y_n - \bar{y})\)</span> from the numerator and <span class="math notranslate nohighlight">\(\sumN \bar{x}(x_n - \bar{x})\)</span> from the denominator without affecting our slope estimate. Finally, we get</p>
<div class="math notranslate nohighlight">
\[
\hat{\beta}_1 = \frac{\sumN (x_n - \bar{x})(y_n - \bar{y})}{\sumN(x_n - \bar{x})^2}.
\]</div>
</div>
</div>
<div class="section" id="multiple-regression">
<h2>2. Multiple Regression<a class="headerlink" href="#multiple-regression" title="Permalink to this headline">¶</a></h2>
<div class="section" id="id1">
<h3>Model Structure<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h3>
<p>In multiple regression, we assume our target variable to be a linear combination of <em>multiple</em> predictor variables. Letting <span class="math notranslate nohighlight">\(x_{nj}\)</span> be the <span class="math notranslate nohighlight">\(j^\text{th}\)</span> predictor for observation <span class="math notranslate nohighlight">\(n\)</span>, we can write the model as</p>
<div class="math notranslate nohighlight">
\[
\begin{align*}
y_n &amp;= \beta_0 + \beta_1x_{n1} + \dots + \beta_D x_{nD} + \epsilon_n.
\end{align*}
\]</div>
<p>Using the vectors <span class="math notranslate nohighlight">\(\bx_n\)</span> and <span class="math notranslate nohighlight">\(\bbeta\)</span> defined in the <a class="reference internal" href="../concept.html"><span class="doc">previous section</span></a>, this can be written more compactly as</p>
<div class="math notranslate nohighlight">
\[
y_n = \bbeta^\top\bx_n + \epsilon_n.
\]</div>
<p>Then define <span class="math notranslate nohighlight">\(\bbetahat\)</span> the same way as <span class="math notranslate nohighlight">\(\bbeta\)</span> except replace the parameters with their estimates. We again want to find the vector <span class="math notranslate nohighlight">\(\hat{\bbeta}\)</span> that minimizes the RSS:</p>
<div class="math notranslate nohighlight">
\[
\mathcal{L}(\bbetahat) = \frac{1}{2}\sumN \left( y_n - \bbetahat^\top \bx_n\right)^2 = \frac{1}{2}\sumN(y_n - \hat{y}_n)^2,
\]</div>
<p>Minimizing this loss function is easier when working with matrices rather than sums. Define <span class="math notranslate nohighlight">\(\by\)</span> and <span class="math notranslate nohighlight">\(\bX\)</span> with</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\by = \begin{bmatrix}y_1 \\ \dots \\ y_N  \end{bmatrix} \in \mathbb{R}^{N}, \hspace{.25cm} \bX = \begin{bmatrix} \bx_1^\top \\ \dots \\ \bx_N^\top  \end{bmatrix} \in \mathbb{R}^{N \times (D+1)},
\end{split}\]</div>
<p>which gives <span class="math notranslate nohighlight">\(\hat{\by} = \bX\bbetahat \in \mathbb{R}^N\)</span>. Then, we can equivalently write the loss function as</p>
<div class="math notranslate nohighlight">
\[
\mathcal{L}(\bbetahat) = \frac{1}{2}(\by - \bX\bbetahat)^\top(\by - \bX\bbetahat).
\]</div>
</div>
<div class="section" id="id2">
<h3>Parameter Estimation<a class="headerlink" href="#id2" title="Permalink to this headline">¶</a></h3>
<p>We can estimate the parameters in the same way as we did for simple linear regression, only this time calculating the derivative of the RSS with respect to the entire parameter vector. First, note the commonly-used matrix derivative below <a class="footnote-reference brackets" href="#ref1" id="id3">1</a>.</p>
<div class="admonition-math-note alert alert-info">
<p class="admonition-title">Math Note</p>
<p>For a symmetric matrix <span class="math notranslate nohighlight">\(\mathbf{W}\)</span>,</p>
<div class="math notranslate nohighlight">
\[
\frac{\partial}{\partial \mathbf{s}}\left(\mathbf{q} - \mathbf{A}\mathbf{s} \right)^\top \mathbf{W} \left(\mathbf{q} - \mathbf{A}\mathbf{s}\right) = -2\mathbf{A}^\top\mathbf{W}\left(\mathbf{q} - \mathbf{A}\mathbf{s}\right)
\]</div>
</div>
<p>Applying the result of the Math Note, we get the derivative of the RSS with respect to <span class="math notranslate nohighlight">\(\bbetahat\)</span> (note that the identity matrix takes the place of <span class="math notranslate nohighlight">\(\mathbf{W}\)</span>):</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
\mathcal{L}(\bbetahat) &amp;= \frac{1}{2}(\by - \bX\bbetahat)^\top(\by - \bX\bbetahat) 
\\
\dadb{\mathcal{L}(\bbetahat)}{\bbetahat} &amp;= - \bX^\top(\by - \bX\bbetahat).
\end{align*}
\end{split}\]</div>
<p>We get our parameter estimates by setting this derivative equal to 0 and solving for <span class="math notranslate nohighlight">\(\bbetahat\)</span>:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
(\bX^\top \bPhi)\bbetahat &amp;= \bX^\top \by \\\
\bbetahat &amp;= (\bX^\top\bX)^\top\bX^\top \by
\end{align}
\end{split}\]</div>
<hr class="docutils" />
<dl class="footnote brackets">
<dt class="label" id="ref1"><span class="brackets"><a class="fn-backref" href="#id3">1</a></span></dt>
<dd><p>A helpful guide for matrix calculus is <a class="reference external" href="https://www.math.uwaterloo.ca/~hwolkowi/matrixcookbook.pdf">The Matrix Cookbook</a></p>
</dd>
</dl>
</div>
</div>
</div>


              </div>
              
        </div>
    </div>
    
    
    <div class='prev-next-bottom'>
        
    <a class='left-prev' id="prev-link" href="../concept.html" title="previous page">Concept</a>
    <a class='right-next' id="next-link" href="likelihood_maximization.html" title="next page">Approach 2: Maximizing Likelihood</a>

    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Danny Friedman<br/>
        
            &copy; Copyright 2020.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    <script src="../../../_static/js/index.js"></script>
    
  </body>
</html>